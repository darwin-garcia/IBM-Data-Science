{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment for Generative AI classroom labs\n",
    "\n",
    "This lab provides a test environment for the codes generated using the Generative AI classroom.\n",
    "\n",
    "Follow the instructions below to set up this environment for further use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n",
    "\n",
    "In case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.9.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (9.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (310)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn nbformat plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "\n",
    "await piplite.install(['nbformat', 'plotly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset URL from the GenAI lab\n",
    "Use the URL provided in the GenAI lab in the cell below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset\n",
    "\n",
    "Execute the following code to download the dataset in to the interface.\n",
    "\n",
    "> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyodide.http import pyfetch\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "path = URL\n",
    "\n",
    "await download(path, \"dataset.csv\")\n",
    "file_name  = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "# Define the file path\n",
    "file_path = URL\n",
    "# Read the CSV file into a pandas data frame\n",
    "data_frame = pd.read_csv(file_path)\n",
    "# Assume the first row of the file can be used as the headers for the data\n",
    "# If the file doesn't have headers, you can remove the 'header' parameter\n",
    "data_frame = pd.read_csv(file_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n",
      "0             0           0         Acer         4    2   1         5   \n",
      "1             1           1         Dell         3    1   1         3   \n",
      "2             2           2         Dell         3    1   1         7   \n",
      "3             3           3         Dell         4    2   1         5   \n",
      "4             4           4           HP         4    2   1         7   \n",
      "\n",
      "   Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n",
      "0              14.0       0.551724       8             256        3.52800   \n",
      "1              15.6       0.689655       4             256        4.85100   \n",
      "2              15.6       0.931034       8             256        4.85100   \n",
      "3              13.3       0.551724       8             128        2.69010   \n",
      "4              15.6       0.620690       8             256        4.21155   \n",
      "\n",
      "   Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n",
      "0    978          Low               0                 1  \n",
      "1    634          Low               1                 0  \n",
      "2    946          Low               1                 0  \n",
      "3   1244          Low               0                 1  \n",
      "4    837          Low               1                 0  \n"
     ]
    }
   ],
   "source": [
    "# Function to read the CSV file into a DataFrame\n",
    "def read_csv_to_dataframe(URL):\n",
    "    # Using pandas read_csv function to load the data\n",
    "    df = pd.read_csv(URL, header=0)  # 0 indicates that the first row should be used as the header\n",
    "    return df\n",
    "\n",
    "# Calling the function and storing the result in a DataFrame\n",
    "laptop_df = read_csv_to_dataframe(URL)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(laptop_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 323461.9325031696\n",
      "Coefficient of Determination (R^2): 0.01619526816734984\n"
     ]
    }
   ],
   "source": [
    "# Extract the source variable and target variable from the data frame\n",
    "X = data_frame[['Screen_Size_inch','Weight_pounds']]\n",
    "y = data_frame['Price']\n",
    "# Initialize a linear regression model\n",
    "model = LinearRegression()\n",
    "# Train the model using the source and target variables\n",
    "model.fit(X, y)\n",
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(X)\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "# Calculate the coefficient of determination (R^2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "# Display the MSE and R^2 values\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficient of Determination (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 285456.29\n",
      "R^2 Score: -0.03\n"
     ]
    }
   ],
   "source": [
    "def read_csv_to_dataframe(URL):\n",
    "    df = pd.read_csv(URL, header=0)  # 0 indicates that the first row is used as the header\n",
    "    return df\n",
    "\n",
    "# Reading the data\n",
    "laptop_df = read_csv_to_dataframe(URL)\n",
    "\n",
    "# For demonstration, let's assume we are predicting \"price\" based on \"screenSize\" and \"weight\"\n",
    "X = laptop_df[['Screen_Size_inch','Weight_pounds']]\n",
    "y = laptop_df['Price']\n",
    "\n",
    "# Split the data into training and testing sets (70% training and 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MSE and R^2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 301773.3728860674\n",
      "Coefficient of Determination (R^2): 0.08216070469589909\n"
     ]
    }
   ],
   "source": [
    "# Extract the source variables and target variable from the data frame\n",
    "X = data_frame[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "y = data_frame['Price']\n",
    "# Initialize a linear regression model\n",
    "model = LinearRegression()\n",
    "# Train the model using the source and target variables\n",
    "model.fit(X, y)\n",
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(X)\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "# Calculate the coefficient of determination (R^2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "# Display the MSE and R^2 values\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficient of Determination (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 272503.80\n",
      "R^2 Score: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Function to read the CSV file into a DataFrame\n",
    "def read_csv_to_dataframe(URL):\n",
    "    df = pd.read_csv(URL, header=0)  # 0 indicates that the first row is used as the header\n",
    "    return df\n",
    "\n",
    "# Reading the data\n",
    "laptop_df = read_csv_to_dataframe(URL)\n",
    "\n",
    "# Let's assume we are predicting \"price\" based on \"screenSize\", \"weight\", and \"storage\"\n",
    "# Here, 'screenSize', 'weight', and 'storage' will be our feature variables (X)\n",
    "X = laptop_df[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "\n",
    "# 'price' will be our target variable (y)\n",
    "y = laptop_df['Price']\n",
    "\n",
    "# Split the data into training and testing sets (70% training and 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MSE and R^2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m]:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Create polynomial features\u001b[39;00m\n\u001b[32m     10\u001b[39m     polynomial_features = PolynomialFeatures(degree=order)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     X_poly = \u001b[43mpolynomial_features\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Initialize a linear regression model\u001b[39;00m\n\u001b[32m     13\u001b[39m     model = LinearRegression()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:327\u001b[39m, in \u001b[36mPolynomialFeatures.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    311\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[33;03m    Compute number of output features.\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m \u001b[33;03m        Fitted transformer.\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     _, n_features = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.shape\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.degree, Integral):\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.degree == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.include_bias:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1086\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1087\u001b[39m             msg = (\n\u001b[32m   1088\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1089\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1090\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1091\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mif it contains a single sample.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1092\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array.dtype, \u001b[33m\"\u001b[39m\u001b[33mkind\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUSV\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "# Extract the source variable and target variable from the data frame\n",
    "X = data_frame['Weight_pounds']\n",
    "y = data_frame['Price']\n",
    "# Initialize lists to store the MSE and R^2 values for each model\n",
    "mse_values = []\n",
    "r2_values = []\n",
    "# Loop through the polynomial orders\n",
    "for order in [2, 3, 5]:\n",
    "    # Create polynomial features\n",
    "    polynomial_features = PolynomialFeatures(degree=order)\n",
    "    X_poly = polynomial_features.fit_transform(X)\n",
    "    # Initialize a linear regression model\n",
    "    model = LinearRegression()\n",
    "    # Train the model using the polynomial features and target variable\n",
    "    model.fit(X_poly, y)\n",
    "    # Make predictions using the trained model\n",
    "    y_pred = model.predict(X_poly)\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    # Calculate the coefficient of determination (R^2)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    # Append the MSE and R^2 values to the lists\n",
    "    mse_values.append(mse)\n",
    "    r2_values.append(r2)\n",
    "    # Display the MSE and R^2 values for the current model\n",
    "    print(f\"Polynomial Order {order}:\")\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Coefficient of Determination (R^2):\", r2)\n",
    "    print()\n",
    "# Compare the performance of the models\n",
    "best_order = np.argmin(mse_values)\n",
    "worst_order = np.argmax(r2_values)\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Best Polynomial Order: {best_order + 2}\")\n",
    "print(f\"Worst Polynomial Order: {worst_order + 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2\n",
      "Mean Squared Error (MSE): 235718.83\n",
      "R^2 Score: 0.15\n",
      "----------------------------------------\n",
      "Degree: 3\n",
      "Mean Squared Error (MSE): 263659.01\n",
      "R^2 Score: 0.05\n",
      "----------------------------------------\n",
      "Degree: 5\n",
      "Mean Squared Error (MSE): 274603.62\n",
      "R^2 Score: 0.01\n",
      "----------------------------------------\n",
      "Degree: 2, MSE: 235718.83, R2: 0.15\n",
      "Degree: 3, MSE: 263659.01, R2: 0.05\n",
      "Degree: 5, MSE: 274603.62, R2: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "laptop_df = read_csv_to_dataframe(URL)\n",
    "\n",
    "# Feature and target variable selection\n",
    "X = laptop_df['Weight_pounds']\n",
    "y = laptop_df['Price']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define polynomial degrees\n",
    "degrees = [2, 3, 5]\n",
    "\n",
    "# List to store the scores\n",
    "scores = []\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train.values.reshape(-1, 1))\n",
    "    X_test_poly = poly.transform(X_test.values.reshape(-1, 1))\n",
    "\n",
    "    # Initialize and train the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    scores.append((degree, mse, r2))\n",
    "    print(f\"Degree: {degree}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"R^2 Score: {r2:.2f}\")\n",
    "    print('-'*40)\n",
    "\n",
    "# Comparing the performance\n",
    "for score in scores:\n",
    "    print(f\"Degree: {score[0]}, MSE: {score[1]:.2f}, R2: {score[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 212563.82853193438\n",
      "Coefficient of Determination (R^2): 0.353490227712864\n"
     ]
    }
   ],
   "source": [
    "# Extract the source variables and target variable from the data frame\n",
    "X = data_frame[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "y = data_frame['Price']\n",
    "# Create a pipeline that performs parameter scaling, polynomial feature generation, and linear regression\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree=2),\n",
    "    LinearRegression()\n",
    ")\n",
    "# Train the model using the source and target variables\n",
    "pipeline.fit(X, y)\n",
    "# Make predictions using the trained model\n",
    "y_pred = pipeline.predict(X)\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "# Calculate the coefficient of determination (R^2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "# Display the MSE and R^2 values\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficient of Determination (R^2):\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 212610.37\n",
      "R^2 Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "X = laptop_df[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "y = laptop_df['Price']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the features\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),  # Generate polynomial features\n",
    "    ('linear', LinearRegression())  # Perform linear regression\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'degree' for estimator Ridge(alpha=0.1). Valid parameters are: ['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'positive', 'random_state', 'solver', 'tol'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m grid_search = GridSearchCV(model, param_grid, cv=\u001b[32m5\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Train the model using the polynomial features and target variable\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Make predictions using the trained model\u001b[39;00m\n\u001b[32m     17\u001b[39m y_pred = grid_search.predict(X_poly)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1017\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1018\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1019\u001b[39m     )\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1027\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1569\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1570\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    962\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    965\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    966\u001b[39m         )\n\u001b[32m    967\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    989\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:854\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    847\u001b[39m score_params_test = _check_method_params(X, params=score_params, indices=test)\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m     \u001b[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001b[39;00m\n\u001b[32m    851\u001b[39m     \u001b[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001b[39;00m\n\u001b[32m    852\u001b[39m     \u001b[38;5;66;03m# estimators in a pipeline.\u001b[39;00m\n\u001b[32m    853\u001b[39m     \u001b[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     estimator = \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m start_time = time.time()\n\u001b[32m    858\u001b[39m X_train, y_train = _safe_split(estimator, X, y, train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:283\u001b[39m, in \u001b[36mBaseEstimator.set_params\u001b[39m\u001b[34m(self, **params)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[32m    282\u001b[39m     local_valid_params = \u001b[38;5;28mself\u001b[39m._get_param_names()\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    284\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     )\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[32m    289\u001b[39m     nested_params[key][sub_key] = value\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter 'degree' for estimator Ridge(alpha=0.1). Valid parameters are: ['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'positive', 'random_state', 'solver', 'tol']."
     ]
    }
   ],
   "source": [
    "# Extract the source variables and target variable from the data frame\n",
    "X = data_frame[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "y = data_frame['Price']\n",
    "# Create polynomial features\n",
    "polynomial_features = PolynomialFeatures()\n",
    "# Transform the source variables into polynomial features\n",
    "X_poly = polynomial_features.fit_transform(X)\n",
    "# Define the hyperparameter values for the grid search\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0], 'degree': [2, 3, 4]}\n",
    "# Initialize a ridge regression model\n",
    "model = Ridge()\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "# Train the model using the polynomial features and target variable\n",
    "grid_search.fit(X_poly, y)\n",
    "# Make predictions using the trained model\n",
    "y_pred = grid_search.predict(X_poly)\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "# Calculate the coefficient of determination (R^2)\n",
    "r2 = r2_score(y, y_pred)\n",
    "# Display the MSE and R^2 values\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficient of Determination (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 212610.37\n",
      "R^2 Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "X = laptop_df[['Screen_Size_inch','Weight_pounds', 'Storage_GB_SSD']]\n",
    "y = laptop_df['Price']\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the features\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),  # Generate polynomial features\n",
    "    ('linear', LinearRegression())  # Perform linear regression\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "prev_pub_hash": "def6c2b16be03b8590d636aa576bdaff4206d1ae9e8a5ace4be932c0f896e5bb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
