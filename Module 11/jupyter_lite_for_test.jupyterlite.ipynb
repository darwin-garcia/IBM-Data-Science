{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment for Generative AI classroom labs\n",
    "\n",
    "This lab provides a test environment for the codes generated using the Generative AI classroom.\n",
    "\n",
    "Follow the instructions below to set up this environment for further use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n",
    "\n",
    "In case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.9.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (9.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (310)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn nbformat plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "\n",
    "await piplite.install(['nbformat', 'plotly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset URL from the GenAI lab\n",
    "Use the URL provided in the GenAI lab in the cell below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset\n",
    "\n",
    "Execute the following code to download the dataset in to the interface.\n",
    "\n",
    "> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyodide.http import pyfetch\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "path = URL\n",
    "\n",
    "await download(path, \"dataset.csv\")\n",
    "file_name  = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Specify the file path\n",
    "file_path = URL\n",
    "# Read the CSV file into a Pandas data frame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n",
      "0           0         Acer         4  IPS Panel    2   1         5   \n",
      "1           1         Dell         3    Full HD    1   1         3   \n",
      "2           2         Dell         3    Full HD    1   1         7   \n",
      "3           3         Dell         4  IPS Panel    2   1         5   \n",
      "4           4           HP         4    Full HD    2   1         7   \n",
      "\n",
      "   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n",
      "0          35.560            1.6       8             256       1.60    978  \n",
      "1          39.624            2.0       4             256       2.20    634  \n",
      "2          39.624            2.7       8             256       2.20    946  \n",
      "3          33.782            1.6       8             128       1.22   1244  \n",
      "4          39.624            1.8       8             256       1.91    837  \n",
      "Local file deleted.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Function to download the CSV file from URL\n",
    "def download_file(URL, local_filename):\n",
    "    with urllib.request.urlopen(URL) as response, open(local_filename, 'wb') as out_file:\n",
    "        out_file.write(response.read())\n",
    "\n",
    "# Local path to save the downloaded file\n",
    "local_filename = \"laptop_pricing_dataset_mod1.csv\"\n",
    "\n",
    "# Download the file\n",
    "download_file(URL, local_filename)\n",
    "\n",
    "# Read the downloaded CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(local_filename)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Optionally clean up: Remove the local file if not needed\n",
    "import os\n",
    "if os.path.exists(local_filename):\n",
    "    os.remove(local_filename)\n",
    "    print(\"Local file deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have a Pandas data frame named 'df'\n",
    "# Identify columns with missing values\n",
    "columns_with_missing_values = df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:  ['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "def find_missing_columns(df):\n",
    "    \"\"\"\n",
    "    Identify columns with missing values in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame to analyze\n",
    "    \n",
    "    Returns:\n",
    "    list: List of column names that contain missing values\n",
    "    \"\"\"\n",
    "    # Identify columns that have missing values\n",
    "    missing_values_presence = df.isnull().sum()\n",
    "    \n",
    "    # Filter columns that have at least one missing value\n",
    "    cols_with_missing = missing_values_presence[missing_values_presence > 0].index.tolist()\n",
    "    \n",
    "    return cols_with_missing\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your DataFrame\n",
    "    # df = pd.read_csv('path_to_your_csv_file.csv')\n",
    "    \n",
    "    example_df = pd.DataFrame({\n",
    "        'A': [1, 2, None, 4],\n",
    "        'B': [5, None, 7, 8],\n",
    "        'C': [9, 10, 11, 12]\n",
    "    })\n",
    "    \n",
    "    missing_cols = find_missing_columns(example_df)\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(\"Columns with missing values: \", missing_cols)\n",
    "    else:\n",
    "        print(\"No columns have missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dangmoz\\AppData\\Local\\Temp\\ipykernel_3752\\3169492310.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Screen_Size_cm'].fillna(most_frequent_value, inplace=True)\n",
      "C:\\Users\\dangmoz\\AppData\\Local\\Temp\\ipykernel_3752\\3169492310.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Weight_kg'].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values in the 'Screen_Size_cm' column with the most frequent value\n",
    "most_frequent_value = df['Screen_Size_cm'].mode()[0]\n",
    "df['Screen_Size_cm'].fillna(most_frequent_value, inplace=True)\n",
    "# Replace missing values in the 'Weight_kg' column with the mean value\n",
    "mean_value = df['Weight_kg'].mean()\n",
    "df['Weight_kg'].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Screen_Size_cm  Weight_kg\n",
      "0             14        1.8\n",
      "1           15.6        2.2\n",
      "2           13.3        2.0\n",
      "3           13.3        1.9\n",
      "4           13.3        2.1\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_values(df):\n",
    "    \"\"\"\n",
    "    Replace missing values in a DataFrame.\n",
    "    \n",
    "    For 'Screen_Size_cm' column, replace missing values with the mode.\n",
    "    For 'Weight_kg' column, replace missing values with the mean.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with filled missing values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copies of columns to work with\n",
    "    screen_size_cm = df['Screen_Size_cm'].copy()\n",
    "    weight_kg = df['Weight_kg'].copy()\n",
    "    \n",
    "    # Find mode for 'Screen_Size_cm'\n",
    "    mode_screen_size = screen_size_cm.mode()[0]\n",
    "    \n",
    "    # Fill NaNs in 'Screen_Size_cm' with mode\n",
    "    screen_size_cm.fillna(mode_screen_size, inplace=True)\n",
    "    \n",
    "    # Calculate mean for 'Weight_kg'\n",
    "    mean_weight = weight_kg.mean()\n",
    "    \n",
    "    # Fill NaNs in 'Weight_kg' with mean\n",
    "    weight_kg.fillna(mean_weight, inplace=True)\n",
    "    \n",
    "    # Update DataFrame\n",
    "    df['Screen_Size_cm'] = screen_size_cm\n",
    "    df['Weight_kg'] = weight_kg\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Screen_Size_cm': ['14', '15.6', np.nan, '13.3', np.nan],\n",
    "        'Weight_kg': [1.8, 2.2, np.nan, 1.9, 2.1]\n",
    "    })\n",
    "    \n",
    "    filled_df = fill_missing_values(df)\n",
    "    \n",
    "    print(filled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of 'Screen_Size_cm' and 'Weight_kg' to float\n",
    "df['Screen_Size_cm'] = df['Screen_Size_cm'].astype(float)\n",
    "df['Weight_kg'] = df['Weight_kg'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Screen_Size_cm  Weight_kg\n",
      "0            14.0        1.8\n",
      "1            15.6        2.2\n",
      "2            13.3        1.9\n",
      "3            14.1        2.1\n"
     ]
    }
   ],
   "source": [
    "def convert_columns_to_float(df, columns):\n",
    "    \"\"\"\n",
    "    Convert specified columns in a DataFrame to float.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    columns (list): List of column names to convert to float\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with specified columns converted to float\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float)\n",
    "    return df\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Screen_Size_cm': ['14.0', '15.6', '13.3', '14.1'],\n",
    "        'Weight_kg': ['1.8', '2.2', '1.9', '2.1']\n",
    "    })\n",
    "    \n",
    "    columns_to_convert = ['Screen_Size_cm', 'Weight_kg']\n",
    "    converted_df = convert_columns_to_float(df, columns_to_convert)\n",
    "    \n",
    "    print(converted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Screen_Size_cm' from centimeters to inches and modify the attribute name\n",
    "df['Screen_Size_inch'] = df['Screen_Size_cm'] * 0.393701\n",
    "df.drop('Screen_Size_cm', axis=1, inplace=True)\n",
    "# Convert 'Weight_kg' from kilograms to pounds and modify the attribute name\n",
    "df['Weight_pounds'] = df['Weight_kg'] * 2.20462\n",
    "df.drop('Weight_kg', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Screen_Size_inch  Weight_pounds\n",
      "0          5.511814       3.968316\n",
      "1          6.141736       4.850164\n",
      "2          5.236223       4.188778\n",
      "3          5.551184       4.629702\n"
     ]
    }
   ],
   "source": [
    "def convert_units(df):\n",
    "    \"\"\"\n",
    "    Convert 'Screen_Size_cm' to 'Screen_Size_inch' and 'Weight_kg' to 'Weight_pounds'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with converted and renamed columns\n",
    "    \"\"\"\n",
    "    # Conversion logic\n",
    "    df['Screen_Size_inch'] = (df['Screen_Size_cm'] * 0.393701).astype(float)\n",
    "    df['Weight_pounds'] = (df['Weight_kg'] * 2.20462).astype(float)\n",
    "    \n",
    "    # Drop the original columns\n",
    "    df.drop(columns=['Screen_Size_cm', 'Weight_kg'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Screen_Size_cm': [14, 15.6, 13.3, 14.1],\n",
    "        'Weight_kg': [1.8, 2.2, 1.9, 2.1]\n",
    "    })\n",
    "    \n",
    "    converted_df = convert_units(df)\n",
    "    \n",
    "    print(converted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CPU_frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'CPU_frequency'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Normalize the content under 'CPU_frequency' with respect to its maximum value\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m max_value = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCPU_frequency\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.max()\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mCPU_frequency\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mCPU_frequency\u001b[39m\u001b[33m'\u001b[39m] / max_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'CPU_frequency'"
     ]
    }
   ],
   "source": [
    "# Normalize the content under 'CPU_frequency' with respect to its maximum value\n",
    "max_value = df['CPU_frequency'].max()\n",
    "df['CPU_frequency'] = df['CPU_frequency'] / max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CPU_frequency\n",
      "0       0.666667\n",
      "1       0.833333\n",
      "2       1.000000\n",
      "3       0.500000\n"
     ]
    }
   ],
   "source": [
    "def normalize_cpu_frequency(df):\n",
    "    \"\"\"\n",
    "    Normalize 'CPU_frequency' column by making its max value 1.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with 'CPU_frequency' column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'CPU_frequency' normalized\n",
    "    \"\"\"\n",
    "    # Find the maximum value in 'CPU_frequency'\n",
    "    max_cpu_freq = df['CPU_frequency'].max()\n",
    "    \n",
    "    # Normalize 'CPU_frequency' by dividing each value by max_cpu_freq\n",
    "    df['CPU_frequency'] = df['CPU_frequency'] / max_cpu_freq\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'CPU_frequency': [2000, 2500, 3000, 1500]\n",
    "    })\n",
    "    \n",
    "    normalized_df = normalize_cpu_frequency(df)\n",
    "    \n",
    "    print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Screen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Screen'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert the 'Screen' attribute into indicator variables\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df1 = pd.get_dummies(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mScreen\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, prefix=\u001b[33m'\u001b[39m\u001b[33mScreen\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Append df1 into the original data frame df\u001b[39;00m\n\u001b[32m      4\u001b[39m df = pd.concat([df, df1], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Screen'"
     ]
    }
   ],
   "source": [
    "# Convert the 'Screen' attribute into indicator variables\n",
    "df1 = pd.get_dummies(df['Screen'], prefix='Screen')\n",
    "# Append df1 into the original data frame df\n",
    "df = pd.concat([df, df1], axis=1)\n",
    "# Drop the original 'Screen' attribute from the data frame\n",
    "df.drop('Screen', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Value  ID  Value  Screen_A  Screen_B  Screen_C\n",
      "0   1     10   1     10      True     False     False\n",
      "1   2     20   2     20     False      True     False\n",
      "2   3     30   3     30      True     False     False\n",
      "3   4     40   4     40     False     False      True\n"
     ]
    }
   ],
   "source": [
    "def convert_to_indicators(df):\n",
    "    \"\"\"\n",
    "    Convert 'Screen' column into indicator variables and append them to the original DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with 'Screen' column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'Screen' converted to indicator variables and appended back\n",
    "    \"\"\"\n",
    "    # Create dummy variables (indicator variables) for the 'Screen' column\n",
    "    df_indicators = pd.get_dummies(df, columns=['Screen'], prefix='Screen')\n",
    "    \n",
    "    # Append the indicator columns to the original DataFrame\n",
    "    df = pd.concat([df, df_indicators], axis=1)\n",
    "    \n",
    "    # Drop the original 'Screen' column\n",
    "    df.drop(columns=['Screen'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df is your original DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [1, 2, 3, 4],\n",
    "        'Value': [10, 20, 30, 40],\n",
    "        'Screen': ['A', 'B', 'A', 'C']\n",
    "    })\n",
    "    \n",
    "    df1 = convert_to_indicators(df)\n",
    "    \n",
    "    print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     Item   Price\n",
      "0   1   Laptop  764.15\n",
      "1   2    Phone  211.65\n",
      "2   3   Tablet  339.15\n",
      "3   4  Glasses  126.65\n"
     ]
    }
   ],
   "source": [
    "def convert_price_to_euro(df, exchange_rate=0.85):\n",
    "    \"\"\"\n",
    "    Convierte los valores de 'Price' del DataFrame de USD a EUR. \n",
    "    \n",
    "    Los valores se multiplican por el tipo de cambio proporcionado (0.85 por defecto, corresponde a 1 USD = 0.85 EUR).\n",
    "    \n",
    "    Parámetros:\n",
    "    df (pd.DataFrame): DataFrame original con columna 'Price' en USD.\n",
    "    exchange_rate (float): Tipo de cambio a utilizar (opcional, se utiliza 0.85 por defecto).\n",
    "    \n",
    "    Devuelve:\n",
    "    pd.DataFrame: DataFrame original con la columna 'Price' convertida a EUR.\n",
    "    \"\"\"\n",
    "    df['Price_EUR'] = df['Price'] * exchange_rate\n",
    "    df.drop('Price', axis=1, inplace=True)\n",
    "    df.rename(columns={'Price_EUR': 'Price'}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Muestreo para el uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Supongamos que df es tu DataFrame original\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [1, 2, 3, 4], \n",
    "        'Item': ['Laptop', 'Phone', 'Tablet', 'Glasses'],\n",
    "        'Price': [899, 249, 399, 149]\n",
    "    })\n",
    "\n",
    "    df_euro = convert_price_to_euro(df)\n",
    "\n",
    "    print(df_euro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     Item  CPU_frequency\n",
      "0   1   Laptop       0.333333\n",
      "1   2    Phone       0.666667\n",
      "2   3   Tablet       1.000000\n",
      "3   4  Glasses       0.000000\n"
     ]
    }
   ],
   "source": [
    "def normalize_cpu_frequency(df):\n",
    "    \"\"\"\n",
    "    Normaliza la columna 'CPU_frequency' del DataFrame mediante la normalización min-max.\n",
    "    \n",
    "    Parámetros:\n",
    "    df (pd.DataFrame): DataFrame original con una columna 'CPU_frequency'.\n",
    "    \n",
    "    Devuelve:\n",
    "    pd.DataFrame: DataFrame original con la columna 'CPU_frequency' normalizada.\n",
    "    \"\"\"\n",
    "    # Calcula el valor mínimo y máximo de 'CPU_frequency'\n",
    "    min_cpu_freq = df['CPU_frequency'].min()\n",
    "    max_cpu_freq = df['CPU_frequency'].max()\n",
    "    \n",
    "    # Aplica la normalización min-max\n",
    "    df['CPU_frequency_normalized'] = (df['CPU_frequency'] - min_cpu_freq) / (max_cpu_freq - min_cpu_freq)\n",
    "    \n",
    "    # Elimine la columna original 'CPU_frequency'\n",
    "    df.drop(columns=['CPU_frequency'], inplace=True)\n",
    "    \n",
    "    # Renomee la nueva columna para reflejar su función\n",
    "    df.rename(columns={'CPU_frequency_normalized': 'CPU_frequency'}, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Supongamos que df es tu DataFrame original\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [1, 2, 3, 4], \n",
    "        'Item': ['Laptop', 'Phone', 'Tablet', 'Glasses'],\n",
    "        'CPU_frequency': [2000, 2500, 3000, 1500]\n",
    "    })\n",
    "\n",
    "    df_normalized = normalize_cpu_frequency(df)\n",
    "\n",
    "    print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "prev_pub_hash": "def6c2b16be03b8590d636aa576bdaff4206d1ae9e8a5ace4be932c0f896e5bb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
