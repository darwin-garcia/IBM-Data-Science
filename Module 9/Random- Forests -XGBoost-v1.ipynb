{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Lab: Comparing Random Forest and XGBoost modeling performance\n",
    "Estimated time needed: **20** minutes\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "* Use scikit-learn to implement Random Forest and XGBoost regression models\n",
    "* Compare the performances of the two models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll create and measure the relative performances of Random Forest and XGBoost regression models for predicting house prices using the California Housing Dataset.\n",
    "'Performance' means both speed and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the libraries that will be required in this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.2.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.6.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.6.0) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dangmoz\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn==1.6.0) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dangmoz\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn==1.6.0) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dangmoz\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn==1.6.0) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.9.3 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib==3.9.3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.3) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==2.1.3 in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dangmoz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost==2.1.3) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\dangmoz\\appdata\\roaming\\python\\python313\\site-packages (from xgboost==2.1.3) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==2.2.0\n",
    "!pip install scikit-learn==1.6.0\n",
    "!pip install matplotlib==3.9.3\n",
    "!pip install xgboost==2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may now start by importing the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: How many observations and features does the dataset have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: 20640\n",
      "Number of Features: 8\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "N_observations, N_features = X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "N_observations, N_features = X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a moderately sized dataset used for this analysis.  \n",
    "Keep in mind you are only using one dataset so you have to consider that the comparison may change with scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize models\n",
    "In this step you define the number of base estimators, or individual trees, to be used in each model, and then intialize models for Random Forest regression and XGBoost regression.  You'll just use the default parameters to make the performance comparisons. As a part of the performance comparison, we'll also measure the training times for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "n_estimators=100\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=n_estimators, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "# Measure training time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time_rf = time.time()\n",
    "rf_train_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure training time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "end_time_xgb = time.time()\n",
    "xgb_train_time = end_time_xgb - start_time_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. Use the fitted models to make predictions on the test set. \n",
    "Also, measure the time it takes for each model to make its predictions using the time.time() function to measure the times before and after each model prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.fit(X_train, y_train)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediction time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_train)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:  Calulate the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'sklearn.ensemble._forest.RandomForestRegressor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Enter your code here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mse_rf = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_rf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n\u001b[32m      5\u001b[39m r2_rf = r2_score(y_test, y_pred_rf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:565\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    516\u001b[39m \n\u001b[32m    517\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    561\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    563\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    564\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m )\n\u001b[32m    569\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    570\u001b[39m output_errors = _average((y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:198\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03mregression task.\u001b[39;00m\n\u001b[32m    150\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m y_type, y_true, y_pred, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:104\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, multioutput, dtype, xp)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    106\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:472\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_consistent_length\u001b[39m(*arrays):\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     lengths = [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    473\u001b[39m     uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:386\u001b[39m, in \u001b[36m_num_samples\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    383\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mExpected sequence or array-like, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(x)\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(x.fit):\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# Don't get num_samples from an ensembles length!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_interchange_protocol(x):\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x.__dataframe__().num_rows()\n",
      "\u001b[31mTypeError\u001b[39m: Expected sequence or array-like, got <class 'sklearn.ensemble._forest.RandomForestRegressor'>"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:  Print the MSE and R^2 values for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mse_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Enter your code here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRandom Forest:  MSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmse_rf\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, R^2 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_rf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m      XGBoost:  MSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_xgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, R2 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_xgb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mse_rf' is not defined"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R2 = {r2_xgb:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the MSE and R^2 values that XGBoost is better than Random Forest, but the differences aren't overwhelming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:  Print the timings for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "\n",
    "print(f'Random Forest:  Training Time = {...:.3f} seconds, Testing time = {...:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {...:.3f} seconds, Testing time = {...:.3f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is very impressive is the difference in computation time between XGBoost and Random Forest for both training and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you want to generate scatter plots between the predicted and actual values for both models so you can visually evaluate how well each model performs.\n",
    "We'll also plot lines one standard deviation of the test data above and below the ideal line, that is, the line that represents the perfect regressor, where the predictions are all correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. Calculate the standard deviation of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "std_y = np. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "``` python\n",
    "# Standard deviation of y_test\n",
    "std_y = np.std(y_test)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediciton time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'Random Forest:  MSE = {mse_rf:.4f}, R^2 = {r2_rf:.4f}')\n",
    "print(f'      XGBoost:  MSE = {mse_xgb:.4f}, R^2 = {r2_xgb:.4f}')\n",
    "print(f'Random Forest:  Training Time = {rf_train_time:.3f} seconds, Testing time = {rf_pred_time:.3f} seconds')\n",
    "print(f'      XGBoost:  Training Time = {xgb_train_time:.3f} seconds, Testing time = {xgb_pred_time:.3f} seconds')\n",
    "std_y = np.std(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Random Forest plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, color=\"blue\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"Random Forest Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# XGBoost plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5, color=\"orange\",ec='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2,label=\"perfect model\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() + std_y, y_test.max() + std_y], 'r--', lw=1, label=\"+/-1 Std Dev\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min() - std_y, y_test.max() - std_y], 'r--', lw=1, )\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"XGBoost Predictions vs Actual\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models performed very well. Most of their predictions fall within a standard deviation of the target. Interestingly, random forest \"respects\" the upper bound (the maximum value) present in the target by staying within its limits, while XGBoost \"overshoots\", or exceeds this limit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You're ready to move on to your next lesson.\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n",
    "\n",
    "### Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" target=\"_blank\">Abhishek Gagneja</a>\n",
    "\n",
    "<!-- ## Changelog\n",
    "\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|:------------|:------|:------------------|:---------------------------------------|\n",
    "| 2024-11-05 | 1.0  | Jeff Grossman    | Create content | -->\n",
    "\n",
    "\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "prev_pub_hash": "c0340e3960777afa61ba00feb3a189a8a1e26c7e0f9f9482c7c5c54268b84f9c"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
